{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfba9429-0093-479f-b454-afaea7de620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load err analysis data\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "class ErrorAnalysisDataset(Dataset):\n",
    "    def __init__(self, dataset_root, pred_split, img_root_dir=None, transform=None):\n",
    "\n",
    "        self.data = pd.read_csv(os.path.join(dataset_root, \"dataset.csv\"))\n",
    "        self.img_root_dir = img_root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        with open(os.path.join(dataset_root, 'mapping.json'), 'r') as f:\n",
    "            self.mapping = json.load(f)\n",
    "            idx_to_mapping = list(self.mapping)\n",
    "            \n",
    "        predictions = pd.read_csv(os.path.join(dataset_root, f\"pred_splits/{pred_split}\"), header=None, names=['pred'])\n",
    "        self.data['pred']=predictions['pred'].values\n",
    "        self.data['pred']=self.data['pred'].apply(lambda pred: self.mapping[idx_to_mapping[pred]])\n",
    "        self.data['gt']=self.data['gt'].apply(lambda pred: self.mapping[idx_to_mapping[pred]])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def load_image(self, img_path):\n",
    "        img_path = os.path.join(self.img_root_dir, img_path)\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure RGB\n",
    "        \n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_root_dir, self.data.iloc[idx]['img_id'])\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure RGB\n",
    "        \n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Extract metadata\n",
    "        attribute = self.data.iloc[idx]['attribute']\n",
    "        gt_code = self.data.iloc[idx]['gt_code']\n",
    "        gt = self.data.iloc[idx]['gt']\n",
    "        pred = self.data.iloc[idx]['pred']\n",
    "\n",
    "        # Return a dictionary with the image and metadata\n",
    "        sample = {\n",
    "            'image': image,\n",
    "            # 'attribute': attribute,\n",
    "            # 'gt_code': gt_code,\n",
    "            # 'gt': gt,\n",
    "            # 'pred': pred\n",
    "        }\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26750db1-d251-4372-bd25-0456d6ab0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Context class that you can add to and read from, should be LLM ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44d5b2e2-14b5-4cf3-9726-fc9cce189b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix analysis module\n",
    "import numpy as np\n",
    "class InitialAnalysis:\n",
    "    def __init__(self, df, prediction_col, ground_truth_col, k=5):\n",
    "        # Get unique classes\n",
    "        classes = sorted(df[ground_truth_col].unique())\n",
    "        \n",
    "        # Initialize confusion matrix\n",
    "        confusion_matrix = pd.DataFrame(\n",
    "            np.zeros((len(classes), len(classes)), dtype=int),\n",
    "            index=classes,\n",
    "            columns=classes\n",
    "        )\n",
    "        \n",
    "        # Populate the confusion matrix\n",
    "        for _, row in df.iterrows():\n",
    "            actual = row[ground_truth_col]\n",
    "            predicted = row[prediction_col]\n",
    "            confusion_matrix.loc[actual, predicted] += 1\n",
    "        \n",
    "        # Extract non-diagonal elements\n",
    "        errors = []\n",
    "        for actual in classes:\n",
    "            for predicted in classes:\n",
    "                if actual != predicted and confusion_matrix.loc[actual, predicted] > 0:\n",
    "                    errors.append(((actual, predicted), confusion_matrix.loc[actual, predicted]))\n",
    "\n",
    "        # Sort errors by count and take top k\n",
    "        top_k_errors = sorted(errors, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.top_k_errors_pred_conditional = top_k_errors\n",
    "        self.k = k\n",
    "        self.classes = classes\n",
    "        \n",
    "    def human_readable_topk_pred_conditional_errors(self):\n",
    "        errors_nl = []\n",
    "        for (actual, predicted), err_count in self.top_k_errors_pred_conditional:\n",
    "            errors_nl.append(f\"The actual class is '{actual}', however model incorrectly predicts '{predicted}' {err_count} times\")\n",
    "            \n",
    "        return '\\n '.join(errors_nl)\n",
    "    \n",
    "    def human_readable_topk_errors_gt(self):\n",
    "        marginal_errs = []\n",
    "        for gt in self.classes:\n",
    "            marginal_errs.append((gt, (self.confusion_matrix.loc[gt].sum()-self.confusion_matrix.loc[gt, gt]).item()))\n",
    "\n",
    "        # select top k\n",
    "        marginal_errs = sorted(marginal_errs, key=lambda x: x[1], reverse=True)[:self.k]\n",
    "        \n",
    "        return f\"The top five marginal errors are for these classes: {marginal_errs}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dca2b4a-3fff-4459-bad2-2c005ff47279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_id</th>\n",
       "      <th>attribute</th>\n",
       "      <th>gt_code</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>n01443537/art_0.jpg</td>\n",
       "      <td>art</td>\n",
       "      <td>n01443537</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>missile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>n01443537/art_1.jpg</td>\n",
       "      <td>art</td>\n",
       "      <td>n01443537</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>goldfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>n01443537/art_10.jpg</td>\n",
       "      <td>art</td>\n",
       "      <td>n01443537</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>soccer_ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>n01443537/art_11.jpg</td>\n",
       "      <td>art</td>\n",
       "      <td>n01443537</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>goldfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>n01443537/art_12.jpg</td>\n",
       "      <td>art</td>\n",
       "      <td>n01443537</td>\n",
       "      <td>goldfish</td>\n",
       "      <td>goldfish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                img_id attribute    gt_code        gt  \\\n",
       "0           0   n01443537/art_0.jpg       art  n01443537  goldfish   \n",
       "1           1   n01443537/art_1.jpg       art  n01443537  goldfish   \n",
       "2           2  n01443537/art_10.jpg       art  n01443537  goldfish   \n",
       "3           3  n01443537/art_11.jpg       art  n01443537  goldfish   \n",
       "4           4  n01443537/art_12.jpg       art  n01443537  goldfish   \n",
       "\n",
       "          pred  \n",
       "0      missile  \n",
       "1     goldfish  \n",
       "2  soccer_ball  \n",
       "3     goldfish  \n",
       "4     goldfish  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it out\n",
    "dataset = ErrorAnalysisDataset(dataset_root='../mock_data_creation/mock_data', pred_split='split_0.txt', img_root_dir='/ix/akovashka/arr159/imagenet-r')\n",
    "dataset.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b8a0762-4aa8-41d2-8dc4-fa1cf832ba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The top five marginal errors are for these classes: [('mushroom', 125), ('toucan', 97), ('flamingo', 96), ('bee', 81), ('jellyfish', 80)]\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = InitialAnalysis(dataset.data, prediction_col='pred', ground_truth_col='gt')\n",
    "analysis.human_readable_topk_errors_gt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a4d5a5-956c-4966-a9c1-743ec24330a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The actual class is 'ant', however model incorrectly predicts 'burrito' 4 times\\n The actual class is 'hotdog', however model incorrectly predicts 'west_highland_white_terrier' 4 times\\n The actual class is 'mushroom', however model incorrectly predicts 'pig' 4 times\\n The actual class is 'tank', however model incorrectly predicts 'parachute' 4 times\\n The actual class is 'African_chameleon', however model incorrectly predicts 'shih_tzu' 3 times\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.human_readable_topk_pred_conditional_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b39137-87d0-4924-a646-fe23b19e0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(data, slice_condition, prediction_col='pred', ground_truth_col='gt', n=10):\n",
    "    # filter data based on slice condition\n",
    "    filtered_data = data[data.apply(slice_condition, axis=1)]\n",
    "    \n",
    "    # divide into error set and non error set\n",
    "    error_set = filtered_data[filtered_data[prediction_col] != filtered_data[ground_truth_col]]\n",
    "    non_error_set = filtered_data[filtered_data[prediction_col] == filtered_data[ground_truth_col]]\n",
    "\n",
    "    # sample n from both sets\n",
    "    sampled_error = error_set.sample(n=min(len(error_set), n), random_state=42)  # Use random_state for reproducibility\n",
    "    sampled_non_error = non_error_set.sample(n=min(len(non_error_set), n), random_state=42)\n",
    "\n",
    "    return sampled_error['img_id'].values, sampled_non_error['img_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec6cd87-acef-446d-947f-3c5e3932bfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['n04086273/art_3.jpg', 'n02108915/misc_42.jpg',\n",
       "        'n01882714/toy_15.jpg', 'n07697537/misc_118.jpg',\n",
       "        'n02356798/cartoon_11.jpg', 'n02094433/misc_37.jpg',\n",
       "        'n07873807/misc_6.jpg', 'n02480855/tattoo_28.jpg',\n",
       "        'n02007558/embroidery_5.jpg', 'n10565667/sketch_3.jpg'],\n",
       "       dtype=object),\n",
       " array(['n03649909/misc_0.jpg', 'n01498041/misc_1.jpg',\n",
       "        'n07768694/toy_0.jpg', 'n02134084/misc_119.jpg',\n",
       "        'n01518878/origami_7.jpg', 'n01833805/misc_4.jpg',\n",
       "        'n02802426/tattoo_6.jpg', 'n02769748/cartoon_4.jpg',\n",
       "        'n01632777/sketch_17.jpg', 'n01843383/embroidery_1.jpg'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(dataset.data, lambda x: True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d9c336-06f2-40e7-9742-ce19a7ac4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727884ceace440568b5711ba05d2af39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load mllm model\n",
    "MAX_LENGTH = 384\n",
    "MODEL_ID = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "import torch\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "processor.tokenizer.padding_side = \"right\" # during training, one always uses padding on the right\n",
    "\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.float16,\n",
    "        # _attn_implementation=\"flash_attention_2\",\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c1bff6c-6778-48b0-8c7c-258f32ca862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The image features a colorful fish painted on a pillar, with a blue background. The fish is the main focus of the scene, and it appears to be a decorative piece or a piece of art. The fish is positioned in the middle of the pillar, and its vibrant colors make it stand out against the blue background.']\n"
     ]
    }
   ],
   "source": [
    "images = [dataset[0]['image']] # testing\n",
    "texts = []\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8de82ee-30d7-4b85-a4e4-0c85c40d89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# captioning, prompt for caption Caption the image with the most salient details\n",
    "\n",
    "def caption_sets(model, processor, dataset, err_list, non_error_list, prompt=\"Caption the image with the most salient details\"):\n",
    "    images = []\n",
    "    texts=[]\n",
    "    images.extend([dataset.load_image(img_path) for img_path in err_list])\n",
    "    images.extend([dataset.load_image(img_path) for img_path in non_error_list])\n",
    "\n",
    "    for img in images:\n",
    "        prompt = f\"USER: <image>\\nCaption the image with the most salient details.\\nASSISTANT:\"\n",
    "        texts.append(prompt)\n",
    "\n",
    "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    input_ids = batch[\"input_ids\"].cuda()\n",
    "    attention_mask = batch[\"attention_mask\"].cuda()\n",
    "    pixel_values = batch[\"pixel_values\"].cuda()\n",
    "    \n",
    "    generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                           pixel_values=pixel_values, max_new_tokens=MAX_LENGTH)\n",
    "    \n",
    "    predictions = processor.batch_decode(generated_ids[:, input_ids.size(1):], skip_special_tokens=True)\n",
    "    \n",
    "    err_list_prompt = [f'A sample with a incorrect prediction has description: ' for i, _ in enumerate(err_list)]\n",
    "    non_err_list_prompt = [f'A sample with a correct prediction has description: ' for i, _ in enumerate(non_error_list)]\n",
    "    return [f'{text}{predictions[i]}' for i, text in enumerate([*err_list_prompt, *non_err_list_prompt])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ce8e337-026e-4712-9f1a-8f0a040ab67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A sample with a incorrect prediction has description: The image features a woman wearing a yellow shirt with a gun design on it. The shirt has a green and red color scheme, and the gun is prominently displayed on the front. The woman appears to be the main focus of the image, and the shirt's design adds a unique touch to her outfit.\",\n",
       " \"A sample with a incorrect prediction has description: The image is a black and white drawing of a small dog with a bow tie. The dog is looking directly at the viewer, capturing attention. The drawing is quite detailed, showcasing the dog's facial features and the bow tie it is wearing. The overall composition of the drawing is visually appealing and captures the essence of the dog's personality.\",\n",
       " 'A sample with a incorrect prediction has description: The image features a stuffed koala bear sitting on a wooden table. The koala is wearing a white shirt and has a brown and white color scheme. The bear is positioned in the center of the scene, occupying a significant portion of the image. The wooden table provides a natural and cozy setting for the stuffed animal.',\n",
       " 'A sample with a incorrect prediction has description: The image features a cute piggy character sitting in a hot dog bun, which is placed on a toy car. The piggy is reading a book, adding a playful and imaginative touch to the scene. The toy car is positioned in the background, and there is a truck visible in the top left corner of the image. The overall scene is a delightful and creative representation of a hot dog bun as a mode of transportation.',\n",
       " \"A sample with a incorrect prediction has description: The image features a small yellow squirrel sitting on a branch. The squirrel is holding a nut in its paws, possibly enjoying a snack. The scene is set against a white background, which highlights the squirrel's vibrant color.\",\n",
       " \"A sample with a incorrect prediction has description: The image features a small, cute dog with a pink bow on its head. The dog is looking directly at the camera, capturing the viewer's attention. The dog is situated in the center of the image, and its adorable appearance makes it the main focus of the scene.\",\n",
       " 'A sample with a incorrect prediction has description: The image features a table with a variety of food items and crafts. There are two pizzas, one with a slice missing and the other with a slice missing as well. A bowl of carrots is also present on the table, along with a plate containing a slice of pizza. \\n\\nIn addition to the food items, there are two teddy bears on the table, one near the center and the other towards the right side. A pair of scissors can be seen on the table, possibly used for cutting the pizza slices. The table appears to be a workspace for crafting, as there are two sewing needles and a pair of scissors, suggesting that someone might be working on a craft project.',\n",
       " \"A sample with a incorrect prediction has description: The image features a large, angry-looking gorilla with its mouth wide open, showing its teeth. The gorilla's face is filled with a mix of orange and yellow colors, giving it a menacing appearance. The gorilla's eyes are open, and its teeth are clearly visible, making it look even more aggressive. The overall scene is quite striking and captures the gorilla's intense expression.\",\n",
       " \"A sample with a incorrect prediction has description: The image features a pink flamingo embroidered on a white cloth. The flamingo is the main focus of the scene, with its distinctive pink color and long legs. The embroidery is intricate and adds a touch of elegance to the cloth. The flamingo's beak is also visible, further emphasizing its unique appearance.\",\n",
       " \"A sample with a incorrect prediction has description: The image features a series of four black and white illustrations of a person wearing a wetsuit and holding a flipper. The person is shown in various positions, such as lying down, sitting, and standing. The illustrations are placed side by side, showcasing the different stages of the person's movement in the water.\",\n",
       " 'A sample with a correct prediction has description: The image is a black and white drawing of a man standing next to a lawn mower. The man is wearing a top hat and appears to be in the process of pushing the mower. The lawn mower is positioned in the lower part of the image, with the man standing on the right side. The scene also features a potted plant located on the left side of the image, adding a touch of greenery to the drawing.',\n",
       " 'A sample with a correct prediction has description: The image features a blue, plastic, three-dimensional object, possibly a toy or a piece of art, sitting on a table. The object appears to be a combination of a boat and a fish, with a fish-like shape on the top and a boat-like structure below. The table is covered with a grid pattern, which adds to the overall visual appeal of the scene.',\n",
       " 'A sample with a correct prediction has description: The image features a large, red apple with a hole in the center, sitting on a wooden table. The apple is placed on a plate, which is resting on a coaster. The coaster is decorated with a floral pattern, adding a touch of elegance to the scene.',\n",
       " 'A sample with a correct prediction has description: The image features a door with a polar bear painted on it. The polar bear is depicted in various positions, including one where it appears to be climbing a mountain. The door also has a sign that reads \"take risks.\" The overall scene is quite unique and eye-catching.',\n",
       " \"A sample with a correct prediction has description: The image features a paper cutout of a bird, possibly a peacock, standing on one leg. The bird is wearing a black and white outfit, giving it a unique appearance. The paper cutout is placed on a table, and the bird's leg is positioned in the foreground, drawing attention to the intricate details of the cutout.\",\n",
       " \"A sample with a correct prediction has description: The image features a colorful bird with a long beak, perched on a thin wooden stick. The bird is painted in a vibrant blue, purple, and red color scheme, making it stand out against the wooden background. The bird's beak is prominently displayed, adding to the overall visual appeal of the scene.\",\n",
       " \"A sample with a correct prediction has description: The image features a tattoo on a person's back, which includes a basketball and angel wings. The tattoo is written in cursive, adding a unique touch to the design. The basketball is positioned in the center of the tattoo, while the angel wings are spread out on either side, creating a visually striking piece of art.\",\n",
       " 'A sample with a correct prediction has description: The image features a man wearing a red shirt and a backpack, walking up a hill. He is holding a walking stick in his hand, and there is a large backpack on his back. The man appears to be hiking or trekking, possibly in a mountainous area. The scene is depicted in a colorful, cartoon-like style, giving it a fun and engaging appearance.',\n",
       " 'A sample with a correct prediction has description: The image features a cartoon-like drawing of a lizard with a sad expression. The lizard is depicted with a long neck and large eyes, giving it a unique and endearing appearance. The drawing is in black and white, adding to the artistic and emotional impact of the scene.',\n",
       " \"A sample with a correct prediction has description: The image features a colorful, hand-woven blanket with a bird design. The bird is prominently displayed in the center of the blanket, surrounded by a lush green forest. The blanket is made of a combination of blue, green, and orange colors, creating a vibrant and eye-catching pattern. The bird's design adds a unique touch to the overall appearance of the blanket.\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "err_list, non_err_list = sample(dataset.data, lambda x: True)\n",
    "\n",
    "caption_sets(model, processor, dataset, err_list, non_err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88cdd4-edfb-4d4c-88a5-70a2d2edc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis + validator class\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e415c2-1e17-473d-b3b1-8c94a22fb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion? max steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7724c04-40dc-46fc-9764-df910af05880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm brain class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
